{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import load_data, CLASSES, data_augmentation, evaluate_model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    AveragePooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Activation,\n",
    "    MaxPool2D,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    ")\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image sizes: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (256, 256)\n",
    "data, labels = load_data(\"./Dataset\", IMG_SIZE=IMG_SIZE)\n",
    "print('Image sizes:', IMG_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val   = train_test_split(data, labels,     test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_val   = np.array(X_val)\n",
    "X_test  = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_val   = np.array(y_val)\n",
    "y_test  = np.array(y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply augmentation on training data\n",
    "X_train_aug, y_train_aug = data_augmentation(X_train, y_train)\n",
    "\n",
    "# apply augmentation on validation data\n",
    "X_val_aug, y_val_aug = data_augmentation(X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 23:17:24.991026: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-20 23:17:24.991073: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ahmed-Nitro-AN515-44): /proc/driver/nvidia/version does not exist\n",
      "2023-05-20 23:17:24.992730: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-20 23:17:25.150009: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-05-20 23:17:25.191218: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2023-05-20 23:17:25.215796: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 1st layer (CONV + pool + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# 2nd layer (CONV + pool + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(BatchNormalization())\n",
    "# layer 3 (CONV + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "# layer 4 (CONV + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "# layer 5 (CONV + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(Flatten())\n",
    "# layer 6 (Dense layer + dropout)\n",
    "model.add(Dense(units=1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "# layer 7 (Dense layers)\n",
    "model.add(Dense(units=1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "# layer 8 (softmax output layer)\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 32, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              16778240  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,146,178\n",
      "Trainable params: 18,145,346\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# describe the model breifly (layers, parameters, ...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-20 23:17:25.332356: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 260702208 exceeds 10% of free system memory.\n",
      "2023-05-20 23:17:25.908378: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 26s 1s/step - loss: 5.9773 - accuracy: 0.6456 - val_loss: 22.3366 - val_accuracy: 0.5108\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 2.5428 - accuracy: 0.7821 - val_loss: 25.3890 - val_accuracy: 0.4703\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.8429 - accuracy: 0.8039 - val_loss: 14.6255 - val_accuracy: 0.4865\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 1.5599 - accuracy: 0.8167 - val_loss: 5.3394 - val_accuracy: 0.6054\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.0542 - accuracy: 0.8499 - val_loss: 3.0725 - val_accuracy: 0.5324\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 1.0120 - accuracy: 0.8582 - val_loss: 2.9084 - val_accuracy: 0.6486\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.8804 - accuracy: 0.8710 - val_loss: 1.7829 - val_accuracy: 0.7486\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.4993 - accuracy: 0.9193 - val_loss: 2.2815 - val_accuracy: 0.7622\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.4567 - accuracy: 0.9253 - val_loss: 1.8608 - val_accuracy: 0.6730\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.4275 - accuracy: 0.9374 - val_loss: 1.2164 - val_accuracy: 0.7838\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.4023 - accuracy: 0.9449 - val_loss: 1.6126 - val_accuracy: 0.7459\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3925 - accuracy: 0.9389 - val_loss: 1.0848 - val_accuracy: 0.8054\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.3321 - accuracy: 0.9600 - val_loss: 1.5936 - val_accuracy: 0.7784\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.2832 - accuracy: 0.9668 - val_loss: 1.1206 - val_accuracy: 0.8135\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2903 - accuracy: 0.9646 - val_loss: 1.4785 - val_accuracy: 0.7649\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.2228 - accuracy: 0.9849 - val_loss: 0.9320 - val_accuracy: 0.8351\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2491 - accuracy: 0.9789 - val_loss: 1.7778 - val_accuracy: 0.7757\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2437 - accuracy: 0.9789 - val_loss: 0.9619 - val_accuracy: 0.8541\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2351 - accuracy: 0.9774 - val_loss: 1.4166 - val_accuracy: 0.7514\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2813 - accuracy: 0.9691 - val_loss: 1.3627 - val_accuracy: 0.7946\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.2428 - accuracy: 0.9744 - val_loss: 1.3537 - val_accuracy: 0.8324\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 21s 997ms/step - loss: 0.2231 - accuracy: 0.9864 - val_loss: 1.4125 - val_accuracy: 0.8243\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.2343 - accuracy: 0.9872 - val_loss: 0.9890 - val_accuracy: 0.8541\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.2130 - accuracy: 0.9827 - val_loss: 1.4291 - val_accuracy: 0.8108\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2284 - accuracy: 0.9804 - val_loss: 2.1259 - val_accuracy: 0.7946\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2383 - accuracy: 0.9789 - val_loss: 2.1291 - val_accuracy: 0.7973\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2201 - accuracy: 0.9834 - val_loss: 3.3421 - val_accuracy: 0.7486\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2203 - accuracy: 0.9789 - val_loss: 1.8281 - val_accuracy: 0.7486\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2156 - accuracy: 0.9842 - val_loss: 1.0893 - val_accuracy: 0.8405\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.1818 - accuracy: 0.9917 - val_loss: 1.0715 - val_accuracy: 0.8649\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2211 - accuracy: 0.9811 - val_loss: 2.6251 - val_accuracy: 0.6730\n",
      "Epoch 32/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2757 - accuracy: 0.9751 - val_loss: 1.7509 - val_accuracy: 0.8243\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2347 - accuracy: 0.9819 - val_loss: 1.8126 - val_accuracy: 0.7351\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2032 - accuracy: 0.9872 - val_loss: 3.5161 - val_accuracy: 0.7757\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2161 - accuracy: 0.9819 - val_loss: 1.7711 - val_accuracy: 0.8108\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.2343 - accuracy: 0.9766 - val_loss: 9.1698 - val_accuracy: 0.6703\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 21s 1s/step - loss: 0.3004 - accuracy: 0.9744 - val_loss: 1.9539 - val_accuracy: 0.8135\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2265 - accuracy: 0.9842 - val_loss: 1.5299 - val_accuracy: 0.7541\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2163 - accuracy: 0.9827 - val_loss: 1.7860 - val_accuracy: 0.8000\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.1962 - accuracy: 0.9849 - val_loss: 2.1569 - val_accuracy: 0.8243\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.1964 - accuracy: 0.9887 - val_loss: 1.6739 - val_accuracy: 0.7676\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.1771 - accuracy: 0.9872 - val_loss: 1.4430 - val_accuracy: 0.8027\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.1606 - accuracy: 0.9955 - val_loss: 2.1026 - val_accuracy: 0.7216\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.1550 - accuracy: 0.9970 - val_loss: 1.7177 - val_accuracy: 0.7568\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2088 - accuracy: 0.9940 - val_loss: 1.3292 - val_accuracy: 0.8351\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 22s 1s/step - loss: 0.2549 - accuracy: 0.9864 - val_loss: 3.6573 - val_accuracy: 0.7568\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2199 - accuracy: 0.9811 - val_loss: 3.5293 - val_accuracy: 0.7189\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2134 - accuracy: 0.9849 - val_loss: 5.8083 - val_accuracy: 0.7108\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.2108 - accuracy: 0.9872 - val_loss: 12.7137 - val_accuracy: 0.6568\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 24s 1s/step - loss: 0.1923 - accuracy: 0.9834 - val_loss: 5.1286 - val_accuracy: 0.7865\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val_aug, y_val_aug)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8324324324324325\n",
      "F1 score:  0.8242145593869732\n",
      "Precision:  0.8732690741243552\n",
      "Recall:  0.8224841660802251\n",
      "Omission error:  0.17751583391977488\n",
      "Commission error:  0.12673092587564483\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(model, X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # 1st layer (CONV + pool + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=96,\n",
    "#         kernel_size=(11, 11),\n",
    "#         strides=(4, 4),\n",
    "#         padding=\"valid\",\n",
    "#         input_shape=(227, 227, 3),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# # 2nd layer (CONV + pool + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=256,\n",
    "#         kernel_size=(5, 5),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\"))\n",
    "# model.add(BatchNormalization())\n",
    "# # layer 3 (CONV + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=384,\n",
    "#         kernel_size=(3, 3),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# # layer 4 (CONV + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=384,\n",
    "#         kernel_size=(3, 3),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# # layer 5 (CONV + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=256,\n",
    "#         kernel_size=(3, 3),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\"))\n",
    "# model.add(Flatten())\n",
    "# # layer 6 (Dense layer + dropout)\n",
    "# model.add(Dense(units=4096, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # layer 7 (Dense layers)\n",
    "# model.add(Dense(units=4096, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # layer 8 (softmax output layer)\n",
    "# model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
