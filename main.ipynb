{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "DATADIR = \"Dataset\"\n",
    "CATEGORIES = [\"flooded\", \"non-flooded\"]\n",
    "data = []\n",
    "labels = []\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        data.append(img_array)\n",
    "        labels.append(CATEGORIES.index(category))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109577/2828977190.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(X_train)\n",
      "/tmp/ipykernel_109577/2828977190.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_val = np.array(X_val)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_val , y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "X_train = np.array(X_train)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def data_augmentation(data, labels):\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    seqs = []\n",
    "    # Define the augmentation sequences\n",
    "    for i in range(2):\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Fliplr(p=random.uniform(0, 1)),\n",
    "            iaa.Crop(percent=(0, random.uniform(0, 0.1))),\n",
    "            iaa.GaussianBlur(sigma=random.uniform(0, 3.0)),\n",
    "            iaa.AdditiveGaussianNoise(scale=(0, random.uniform(0, 0.1*255))),\n",
    "            iaa.Multiply((random.uniform(0.5, 1.5), random.uniform(0.5, 1.5))),\n",
    "            iaa.Affine(\n",
    "                scale={\"x\": (random.uniform(0.8, 1.2), random.uniform(0.8, 1.2)), \"y\": (random.uniform(0.8, 1.2), random.uniform(0.8, 1.2))},\n",
    "                translate_percent={\"x\": (random.uniform(-0.2, 0.2), random.uniform(-0.2, 0.2)), \"y\": (random.uniform(-0.2, 0.2), random.uniform(-0.2, 0.2))},\n",
    "                rotate=(random.uniform(-45, 45), random.uniform(-45, 45)),\n",
    "                shear=(random.uniform(-16, 16), random.uniform(-16, 16))\n",
    "            )\n",
    "        ], random_order=True)\n",
    "        seqs.append(seq)\n",
    "\n",
    "    for i, image in enumerate(data):\n",
    "        if i % 100 == 0:\n",
    "            print(i)\n",
    "        augmented_images.append(image)\n",
    "        augmented_labels.append(labels[i])\n",
    "        for seq in seqs:\n",
    "            augmented_image = seq(image=image)\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(labels[i])\n",
    "    \n",
    "    return np.array(augmented_images), np.array(augmented_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# apply augmentation on training data\n",
    "X_train_aug, y_train_aug = data_augmentation(X_train, y_train)\n",
    "\n",
    "# apply augmentation on validation data\n",
    "X_val_aug, y_val_aug = data_augmentation(X_val, y_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(image):\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.resize(image, (227 , 227))\n",
    "    return image\n",
    "\n",
    "X_train_aug = np.array([extract_image_features(image) for image in X_train_aug])\n",
    "X_val_aug = np.array([extract_image_features(image) for image in X_val_aug])\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train_aug = to_categorical(y_train_aug)\n",
    "y_val_aug = to_categorical(y_val_aug)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    AveragePooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Activation,\n",
    "    MaxPool2D,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# # 1st layer (CONV + pool + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=96,\n",
    "#         kernel_size=(11, 11),\n",
    "#         strides=(4, 4),\n",
    "#         padding=\"valid\",\n",
    "#         input_shape=(227, 227, 3),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "# model.add(BatchNormalization())\n",
    "# # 2nd layer (CONV + pool + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=256,\n",
    "#         kernel_size=(5, 5),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\"))\n",
    "# model.add(BatchNormalization())\n",
    "# # layer 3 (CONV + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=384,\n",
    "#         kernel_size=(3, 3),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# # layer 4 (CONV + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=384,\n",
    "#         kernel_size=(3, 3),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# # layer 5 (CONV + batchnorm)\n",
    "# model.add(\n",
    "#     Conv2D(\n",
    "#         filters=256,\n",
    "#         kernel_size=(3, 3),\n",
    "#         strides=(1, 1),\n",
    "#         padding=\"same\",\n",
    "#         kernel_regularizer=l2(0.0005),\n",
    "#     )\n",
    "# )\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPool2D(pool_size=(3, 3), strides=(2, 2), padding=\"valid\"))\n",
    "# model.add(Flatten())\n",
    "# # layer 6 (Dense layer + dropout)\n",
    "# model.add(Dense(units=4096, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # layer 7 (Dense layers)\n",
    "# model.add(Dense(units=4096, activation=\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # layer 8 (softmax output layer)\n",
    "# model.add(Dense(units=2, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# 1st layer (CONV + pool + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        input_shape=(227, 227, 3),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# 2nd layer (CONV + pool + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(BatchNormalization())\n",
    "# layer 3 (CONV + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "# layer 4 (CONV + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "# layer 5 (CONV + batchnorm)\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=(3, 3),\n",
    "        strides=(1, 1),\n",
    "        padding=\"same\",\n",
    "        kernel_regularizer=l2(0.0005),\n",
    "    )\n",
    ")\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding=\"valid\"))\n",
    "model.add(Flatten())\n",
    "# layer 6 (Dense layer + dropout)\n",
    "model.add(Dense(units=1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "# layer 7 (Dense layers)\n",
    "model.add(Dense(units=1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "# layer 8 (softmax output layer)\n",
    "model.add(Dense(units=2, activation=\"softmax\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=7, validation_data=(X_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get confusion matrix , f1 score\n",
    "# Plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=CATEGORIES, columns=CATEGORIES)\n",
    "sns.heatmap(cm_df, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Plot f1 score\n",
    "f1 = f1_score(y_val, y_pred, average=None)\n",
    "f1_df = pd.DataFrame(f1, index=CATEGORIES, columns=[\"F1 Score\"])\n",
    "f1_df.plot(kind=\"bar\", ylim=(0, 1))\n",
    "plt.title(\"F1 Score\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
